{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Utils"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72abf790fb4a74db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63013586d3dd592f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "from environments.alfworld.common.environment import ALFWorldEnv\n",
    "from environments.alfworld.adapt.generate_prompts import generate_openai_tools_prompt\n",
    "from environments.alfworld.adapt.plan_prompts import plan_prompt\n",
    "from environments.alfworld.adapt.plan_output_parser import ALFWorldADaPTPPlanOutputParser\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from planning_library.strategies import ADaPTStrategy\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:32.362556Z",
     "start_time": "2024-03-27T17:26:30.077371Z"
    }
   },
   "id": "917b334526ae1418",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logging"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d03be61eb1d2d978"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ALFWorld + ADaPT\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:32.380577Z",
     "start_time": "2024-03-27T17:26:32.362967Z"
    }
   },
   "id": "add6277843d9e0d5",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49b12b291a70bf6a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing AlfredTWEnv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8810/8810 [00:03<00:00, 2921.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall we have 3553 games in split=train\n",
      "Training with 3553 games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"ALFWORLD_DATA\"] = \"utils/data\"\n",
    "\n",
    "if not \"base_config.yaml\" in os.listdir(\"utils\"):\n",
    "    response = requests.get(\"https://raw.githubusercontent.com/alfworld/alfworld/master/configs/base_config.yaml\")\n",
    "    \n",
    "    with open(\"utils/base_config.yaml\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "env = ALFWorldEnv(config_path=\"utils/base_config.yaml\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:35.836079Z",
     "start_time": "2024-03-27T17:26:32.380956Z"
    }
   },
   "id": "a79748e60e33a68c",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-= Welcome to TextWorld, ALFRED! =-\n",
      "\n",
      "You are in the middle of a room. Looking quickly around you, you see a bed 1, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a desk 1, a drawer 2, a drawer 1, a garbagecan 1, a shelf 1, and a sidetable 1.\n",
      "\n",
      "Your task is to: put some pencil on shelf.\n"
     ]
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "print(obs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:36.425055Z",
     "start_time": "2024-03-27T17:26:35.835494Z"
    }
   },
   "id": "e6feb0742d5fd134",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Strategy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c73a0b66343809e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ea5dbf565405291"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ADaPT hyperparameters\n",
    "max_depth = 3  # maximum decomposition depth\n",
    "executor_max_iterations = 20  # maximum number of iterations for the executor; when reached, the loop will exit\n",
    "\n",
    "# other hyperparameters\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "temperature = 0.8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:36.444993Z",
     "start_time": "2024-03-27T17:26:36.420719Z"
    }
   },
   "id": "95866c282598a829",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Executor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be5638126da22e9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Default Executor is powered by any strategy from the library. By default, a simple one is used (see `planning_library/strategies/simple/simple_strategy.py` for more details)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a668ccc0e924025"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompt\n",
    "\n",
    "Here is an example of a simple prompt suitable for ALFWorld with ADaPT."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdab05c929dfb027"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['agent_scratchpad', 'inputs']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_openai_tools_prompt.input_variables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:36.460688Z",
     "start_time": "2024-03-27T17:26:36.438943Z"
    }
   },
   "id": "53b82cb72e1332d2",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are ALFRED, an intelligent agent navigating in a household.\n",
      "Human: -= Welcome to TextWorld, ALFRED! =-\n",
      "\n",
      "You are in the middle of a room. Looking quickly around you, you see a bed 1, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a desk 1, a drawer 2, a drawer 1, a garbagecan 1, a shelf 1, and a sidetable 1.\n",
      "\n",
      "Your task is to: put some pencil on shelf.\n",
      "Human: Use observations from an environment to judge whether you have solved the task successfully. When you are sure that you have successfully completed the task, make sure to include the words 'task completed' in your output. Do not write 'task completed' if the task has not been completed.\n"
     ]
    }
   ],
   "source": [
    "print(generate_openai_tools_prompt.format(inputs=obs, agent_scratchpad=[]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:36.476989Z",
     "start_time": "2024-03-27T17:26:36.458253Z"
    }
   },
   "id": "6cf24e3f1a72a421",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[GoToTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n OpenTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n CloseTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n TakeTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n PutTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n ToggleTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n HeatTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n CoolTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n CleanTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n ExamineTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n InventoryTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>),\n LookTool(env=<textworld.gym.envs.textworld_batch.TextworldBatchGymEnv object at 0x16fba29d0>)]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = env.tools\n",
    "tools"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:36.500184Z",
     "start_time": "2024-03-27T17:26:36.477068Z"
    }
   },
   "id": "e4fa20b4d1561e0",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Putting It All Together\n",
    "\n",
    "Let's use [OpenAI Tools](https://python.langchain.com/docs/modules/agents/agent_types/openai_tools) agent."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9087fe3c6c96b6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "# copied from langchain.agents.create_openai_tools_agent to allow for custom inputs processing\n",
    "llm = ChatOpenAI(model=model_name, temperature=temperature).bind(tools=[convert_to_openai_tool(tool) for tool in tools])\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"inputs\": itemgetter(\"inputs\") | RunnableLambda(itemgetter(\"inputs\")),\n",
    "        \"agent_scratchpad\": itemgetter(\"intermediate_steps\") | RunnableLambda(format_to_openai_tool_messages),\n",
    "    }\n",
    "    | generate_openai_tools_prompt\n",
    "    | llm\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:36.594282Z",
     "start_time": "2024-03-27T17:26:36.495936Z"
    }
   },
   "id": "74d79f1439d28be4",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2db49967fa84c859"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Planner\n",
    "\n",
    "Default Planner is powered by a [`Runnable`](https://python.langchain.com/docs/expression_language/interface) that takes in:\n",
    "\n",
    "* `inputs`: original inputs\n",
    "* `intermediate_steps`: a sequence of agent actions\n",
    "* `agent_outcome`: final answer\n",
    "\n",
    "It should output a sequence of subtasks and a logic for executing those subtasks (either and or or)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f6d98010f0d114"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45c1ebe3ca8c3e3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['agent_outcome', 'inputs', 'intermediate_steps']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan_prompt.input_variables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:36.617226Z",
     "start_time": "2024-03-27T17:26:36.594548Z"
    }
   },
   "id": "9e88f0f2f6600d07",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an advanced reasoning agent that can create plans for reasoning tasks.\n",
      "Human: \n",
      "The task at hand is a household navigation. An attempt to solve it directly has failed, and you need to create a clear and concise plan instead.\n",
      "\n",
      "You will be given the task description, all the intermediate steps that were taken during the last trial and the final outcome. \n",
      "\n",
      "Task description:\n",
      "-= Welcome to TextWorld, ALFRED! =-\n",
      "\n",
      "You are in the middle of a room. Looking quickly around you, you see a bed 1, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a desk 1, a drawer 2, a drawer 1, a garbagecan 1, a shelf 1, and a sidetable 1.\n",
      "\n",
      "Your task is to: put some pencil on shelf.\n",
      "Human: Intermediate steps:\n",
      "Human: Final outcome: <something>\n",
      "Human: \n",
      "Please, output a step-by-step plan for how to solve the task successfully. Use the following format:\n",
      "```\n",
      "Step 1: <Description of first step>\n",
      "Step 2: <Description of second step>\n",
      "...\n",
      "Step N: <Description of Nth step>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(plan_prompt.format(inputs=obs, intermediate_steps=[], agent_outcome=\"<something>\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:36.634369Z",
     "start_time": "2024-03-27T17:26:36.612291Z"
    }
   },
   "id": "7dfe9fd3f5e460fd",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Putting It All Together"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0096992048e5766"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "planner_runnable = (\n",
    "    {\n",
    "        \"inputs\": itemgetter(\"inputs\") | RunnableLambda(itemgetter(\"inputs\")),\n",
    "        \"agent_outcome\": itemgetter(\"agent_outcome\") | RunnableLambda(lambda x: x.log),\n",
    "        \"intermediate_steps\": itemgetter(\"intermediate_steps\") | RunnableLambda(format_to_openai_tool_messages),\n",
    "    }\n",
    "    | plan_prompt\n",
    "    | ChatOpenAI(model=model_name, temperature=temperature)\n",
    "    | ALFWorldADaPTPPlanOutputParser()\n",
    ").with_config(run_name=\"Generate Plan\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:36.660418Z",
     "start_time": "2024-03-27T17:26:36.631268Z"
    }
   },
   "id": "b79242542d422b53",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining strategy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1ebe94eff77889e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from planning_library.action_executors import GymnasiumActionExecutor\n",
    "\n",
    "\n",
    "action_executor = GymnasiumActionExecutor(env)\n",
    "adapt = ADaPTStrategy.create(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    action_executor=action_executor,\n",
    "    planner_runnable=planner_runnable,\n",
    "    executor_max_iterations=executor_max_iterations,\n",
    "    max_depth=max_depth,\n",
    "    executor_return_intermediate_steps=True,\n",
    "    executor_return_finish_log=True,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:36.676370Z",
     "start_time": "2024-03-27T17:26:36.658420Z"
    }
   },
   "id": "d7c2708702ec7712",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ADaPTStrategy chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleStrategy chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mTask completed. The pencil has been successfully put on the shelf.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mTask completed. The pencil has been successfully put on the shelf.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'inputs': {'inputs': '-= Welcome to TextWorld, ALFRED! =-\\n\\nYou are in the middle of a room. Looking quickly around you, you see a bed 1, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a desk 1, a drawer 2, a drawer 1, a garbagecan 1, a shelf 1, and a sidetable 1.\\n\\nYour task is to: put some pencil on shelf.'},\n 'intermediate_steps': [[(OpenAIToolAgentAction(tool='goto', tool_input={'receptable_type': 'shelf', 'receptable_id': 1}, log=\"\\nInvoking: `goto` with `{'receptable_type': 'shelf', 'receptable_id': 1}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_wUX8oCgyzqSub034JLHVm2R7', 'function': {'arguments': '{\"receptable_type\":\"shelf\",\"receptable_id\":1}', 'name': 'goto'}, 'type': 'function'}]})], tool_call_id='call_wUX8oCgyzqSub034JLHVm2R7'),\n    {'observation': 'You arrive at loc 9. On the shelf 1, you see a keychain 2, and a pen 1.',\n     'reward': 0,\n     'terminated': False,\n     'truncated': False,\n     'info': {}}),\n   (OpenAIToolAgentAction(tool='put', tool_input={'object_id': 1, 'object_type': 'pencil', 'receptable_id': 1, 'receptable_type': 'shelf'}, log=\"\\nInvoking: `put` with `{'object_id': 1, 'object_type': 'pencil', 'receptable_id': 1, 'receptable_type': 'shelf'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_ExF0sneK90vXsehXVcxmQSLG', 'function': {'arguments': '{\"object_id\":1,\"object_type\":\"pencil\",\"receptable_id\":1,\"receptable_type\":\"shelf\"}', 'name': 'put'}, 'type': 'function'}]})], tool_call_id='call_ExF0sneK90vXsehXVcxmQSLG'),\n    {'observation': 'Nothing happens.',\n     'reward': 0,\n     'terminated': False,\n     'truncated': False,\n     'info': {}}),\n   (OpenAIToolAgentAction(tool='take', tool_input={'object_id': 1, 'object_type': 'pencil', 'receptable_id': 1, 'receptable_type': 'sidetable'}, log=\"\\nInvoking: `take` with `{'object_id': 1, 'object_type': 'pencil', 'receptable_id': 1, 'receptable_type': 'sidetable'}`\\nresponded: The pencil was not successfully put on the shelf. Let me try again.\\n\\n\", message_log=[AIMessageChunk(content='The pencil was not successfully put on the shelf. Let me try again.', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_2WKPuhj0CjhTEdS5Qev5KpGR', 'function': {'arguments': '{\"object_id\":1,\"object_type\":\"pencil\",\"receptable_id\":1,\"receptable_type\":\"sidetable\"}', 'name': 'take'}, 'type': 'function'}]})], tool_call_id='call_2WKPuhj0CjhTEdS5Qev5KpGR'),\n    {'observation': 'Nothing happens.',\n     'reward': 0,\n     'terminated': False,\n     'truncated': False,\n     'info': {}}),\n   (OpenAIToolAgentAction(tool='put', tool_input={'object_id': 1, 'object_type': 'pencil', 'receptable_id': 1, 'receptable_type': 'shelf'}, log=\"\\nInvoking: `put` with `{'object_id': 1, 'object_type': 'pencil', 'receptable_id': 1, 'receptable_type': 'shelf'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRVpS72uSFs8m7wMnaK5DQV0', 'function': {'arguments': '{\"object_id\":1,\"object_type\":\"pencil\",\"receptable_id\":1,\"receptable_type\":\"shelf\"}', 'name': 'put'}, 'type': 'function'}]})], tool_call_id='call_BRVpS72uSFs8m7wMnaK5DQV0'),\n    {'observation': 'Nothing happens.',\n     'reward': 0,\n     'terminated': False,\n     'truncated': False,\n     'info': {}}),\n   (OpenAIToolAgentAction(tool='goto', tool_input={'receptable_type': 'sidetable', 'receptable_id': 1}, log=\"\\nInvoking: `goto` with `{'receptable_type': 'sidetable', 'receptable_id': 1}`\\nresponded: It seems that I can't put the pencil on the shelf directly. Let me try a different approach.\\n\\n\", message_log=[AIMessageChunk(content=\"It seems that I can't put the pencil on the shelf directly. Let me try a different approach.\", additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_blOoeqzZNAytPxLMRfuG23kI', 'function': {'arguments': '{\"receptable_type\":\"sidetable\",\"receptable_id\":1}', 'name': 'goto'}, 'type': 'function'}]})], tool_call_id='call_blOoeqzZNAytPxLMRfuG23kI'),\n    {'observation': 'You arrive at loc 15. On the sidetable 1, you see a cd 1, a cellphone 2, a cellphone 1, and a pencil 1.',\n     'reward': 0,\n     'terminated': False,\n     'truncated': False,\n     'info': {}}),\n   (OpenAIToolAgentAction(tool='take', tool_input={'object_id': 1, 'object_type': 'pencil', 'receptable_id': 1, 'receptable_type': 'sidetable'}, log=\"\\nInvoking: `take` with `{'object_id': 1, 'object_type': 'pencil', 'receptable_id': 1, 'receptable_type': 'sidetable'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_UpDV6NT2mqzaKj43dyRR3Hkt', 'function': {'arguments': '{\"object_id\":1,\"object_type\":\"pencil\",\"receptable_id\":1,\"receptable_type\":\"sidetable\"}', 'name': 'take'}, 'type': 'function'}]})], tool_call_id='call_UpDV6NT2mqzaKj43dyRR3Hkt'),\n    {'observation': 'You pick up the pencil 1 from the sidetable 1.',\n     'reward': 0,\n     'terminated': False,\n     'truncated': False,\n     'info': {}}),\n   (OpenAIToolAgentAction(tool='goto', tool_input={'receptable_type': 'shelf', 'receptable_id': 1}, log=\"\\nInvoking: `goto` with `{'receptable_type': 'shelf', 'receptable_id': 1}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_qEUVTtaS7yB8Uoa7BNVciIEo', 'function': {'arguments': '{\"receptable_type\":\"shelf\",\"receptable_id\":1}', 'name': 'goto'}, 'type': 'function'}]})], tool_call_id='call_qEUVTtaS7yB8Uoa7BNVciIEo'),\n    {'observation': 'You arrive at loc 9. On the shelf 1, you see a keychain 2, and a pen 1.',\n     'reward': 0,\n     'terminated': False,\n     'truncated': False,\n     'info': {}}),\n   (OpenAIToolAgentAction(tool='put', tool_input={'object_id': 1, 'object_type': 'pencil', 'receptable_id': 1, 'receptable_type': 'shelf'}, log=\"\\nInvoking: `put` with `{'object_id': 1, 'object_type': 'pencil', 'receptable_id': 1, 'receptable_type': 'shelf'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_ETFnfShRwkTOKd5PYwqdj224', 'function': {'arguments': '{\"object_id\":1,\"object_type\":\"pencil\",\"receptable_id\":1,\"receptable_type\":\"shelf\"}', 'name': 'put'}, 'type': 'function'}]})], tool_call_id='call_ETFnfShRwkTOKd5PYwqdj224'),\n    {'observation': 'You put the pencil 1 in/on the shelf 1.',\n     'reward': 1,\n     'terminated': True,\n     'truncated': False,\n     'info': {}})]]}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapt.invoke(\n",
    "    {\"inputs\": {\"inputs\": obs}}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:26:52.111819Z",
     "start_time": "2024-03-27T17:26:36.677743Z"
    }
   },
   "id": "8d1b5178959c06",
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
