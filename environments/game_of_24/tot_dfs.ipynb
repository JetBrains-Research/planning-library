{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Game of 24: ToT + DFS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f870728b8f42286"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utils"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac15008844246559"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8bf9aec03e431bc"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from environments.game_of_24.common.evaluate_parser import GameOf24EvaluateOutputParser\n",
    "from environments.game_of_24.tot_dfs.evaluate_prompts import evaluate_prompt\n",
    "from environments.game_of_24.tot_dfs.generate_prompts import generate_sample_openai_tools_prompt\n",
    "from planning_library.strategies import TreeOfThoughtsDFSStrategy\n",
    "from planning_library.strategies.tot_dfs.components import (\n",
    "    ThoughtEvaluator,\n",
    "    AgentThoughtGenerator,\n",
    "    RunnableThoughtEvaluator,\n",
    "    ThresholdThoughtEvaluatorContinueJudge,\n",
    ")\n",
    "from operator import itemgetter\n",
    "from langchain_core.agents import AgentAction, AgentFinish, AgentStep\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import List, Union, Optional\n",
    "from environments.game_of_24.common.simple_tools import add, subtract, multiply, divide\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:10.276709Z",
     "start_time": "2024-03-06T16:52:10.259579Z"
    }
   },
   "id": "c94d0bfae6ac52b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Enabling logging"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8cba987fa8f60c4"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
    "# os.environ[\"WANDB_PROJECT\"] = \"aeliseeva-tot-dfs-game24-test\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:10.578314Z",
     "start_time": "2024-03-06T16:52:10.566570Z"
    }
   },
   "id": "b839c1569a02b9e1"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ToT + Game of 24 test\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:10.813387Z",
     "start_time": "2024-03-06T16:52:10.798138Z"
    }
   },
   "id": "7d8838345955d3c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining components"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99565d7bf09a28b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "783935cd06fec74d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# ToT hyperparameters\n",
    "max_num_thoughts = 3  # number of thoughts to generate at each iteration\n",
    "max_num_steps = 20  # total maximum number of iterations\n",
    "value_threshold = 0.49  # threshold for evaluation; only thoughts with value > value_threshold will be explored\n",
    "\n",
    "# other hyperparameters\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "temperature = 0.8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:11.551576Z",
     "start_time": "2024-03-06T16:52:11.532667Z"
    }
   },
   "id": "3b1ff5faf3a98a79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Thought Evaluator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d8fdcea67bf22ee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Thought Evaluator** is responsible for evaluating the plausibility of individual thoughts.\n",
    "\n",
    "Default **Thought Evaluator** is powered by a [`Runnable`](https://python.langchain.com/docs/expression_language/interface) that takes in:\n",
    "\n",
    "* `inputs`: original inputs\n",
    "* `trajectory`: a sequence of agent actions up to current node\n",
    "* `next_thought`: a current suggestion for the next step (either finish or call tool(s))\n",
    "* `observation`: `None` if `next_thought` is `AgentFinish`, otherwise, the result of tool call(s)\n",
    "\n",
    "The runnable is allowed to return anything. In this case, it returns a float ranging from 0 to 1.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7af9f540360a932"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16db988515e83619"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is a simple prompt for Thought Evaluator in Game of 24."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d25c860d110aa95d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "['inputs', 'next_thought', 'observation', 'trajectory']"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_prompt.input_variables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:13.354135Z",
     "start_time": "2024-03-06T16:52:13.335942Z"
    }
   },
   "id": "fd1913a8499f4b85"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant that judges whether answers to Game of 24 are correct or individual steps to reach 24 from given numbers seem plausible.\n",
      "Human: You are given inputs and intermediate steps for Game of 24: the goal is to reach 24 via arithmetical operations on given numbers. In your case, Game of 24 is played in step-by-step fashion: each suggestion is an arithmetical operation between two numbers. You might be given either a suggestion (a single arithmetical operation on two numbers) or a final answer (mathematical expression that should be equal to 24). In the former case, evaluate if a new suggestion is correct and how likely it is to help in reaching 24. In the latter case, evaluate if the final answer is correct, i.e., uses each input number exactly once. You are allowed to comment your decision, but make sure to always output one of the following words in the end: 'sure', 'likely', 'impossible'.\n",
      "Human: Input: 2 3 6 4\n",
      "AI: Suggestion: 2 + 3 = 5\n",
      "Human: Judge:\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_prompt.format(inputs=\"2 3 6 4\", trajectory=[], next_thought=\"2 + 3\", observation=\"5\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:13.686098Z",
     "start_time": "2024-03-06T16:52:13.676910Z"
    }
   },
   "id": "5df9493e9fd2d2ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Formatting Utils"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ff85eba1b3307e1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "\n",
    "\n",
    "op_map = {\"add\": \"+\", \"subtract\": \"-\", \"multiply\": \"*\", \"divide\": \"/\"}\n",
    "\n",
    "\n",
    "def format_observation(observation: Optional[Union[List[AgentStep], AgentStep]]) -> Optional[str]:\n",
    "    if observation is None:\n",
    "        return None\n",
    "\n",
    "    if isinstance(observation, list):\n",
    "        return \";\".join(format_observation(obs) for obs in observation)\n",
    "\n",
    "    return str(observation.observation)\n",
    "\n",
    "\n",
    "def format_next_thought(next_thought: Union[List[AgentAction], AgentAction, AgentFinish]) -> str:\n",
    "    if isinstance(next_thought, AgentAction):\n",
    "        number1 = next_thought.tool_input[\"number1\"]\n",
    "        number2 = next_thought.tool_input[\"number2\"]\n",
    "        return f\"{number1} {op_map[next_thought.tool]} {number2}\"\n",
    "    elif isinstance(next_thought, AgentFinish):\n",
    "        return next_thought.log\n",
    "    else:\n",
    "        # ugly hack, because it ignores an instruction to generate one action per step ><\n",
    "        return format_next_thought(next_thought[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:14.720076Z",
     "start_time": "2024-03-06T16:52:14.705318Z"
    }
   },
   "id": "6a1d03b446643eee",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Putting It All Together"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acd822dcdd645d79"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "evaluator_chain = (\n",
    "    {\n",
    "        \"inputs\": RunnableLambda(lambda x: x[\"inputs\"][\"inputs\"]),\n",
    "        \"trajectory\": itemgetter(\"trajectory\") | RunnableLambda(format_to_openai_tool_messages),\n",
    "        \"observation\": itemgetter(\"observation\") | RunnableLambda(format_observation),\n",
    "        \"next_thought\": itemgetter(\"next_thought\") | RunnableLambda(format_next_thought),\n",
    "    }\n",
    "    | evaluate_prompt\n",
    "    | ChatOpenAI(model=model_name, temperature=temperature)\n",
    "    | GameOf24EvaluateOutputParser()\n",
    ")\n",
    "\n",
    "judge = ThresholdThoughtEvaluatorContinueJudge(value_threshold)\n",
    "backbone = RunnableThoughtEvaluator(evaluator_chain)\n",
    "thought_evaluator = ThoughtEvaluator(judge=judge, backbone=backbone)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:15.665232Z",
     "start_time": "2024-03-06T16:52:15.639407Z"
    }
   },
   "id": "d69a6c54ea18ee57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Thought Generator\n",
    "\n",
    "**Thought Generator** is responsible for suggesting possible actions on each new step.\n",
    "\n",
    "Default **Thought Generator** is powered by [any agent available in LangChain](https://python.langchain.com/docs/modules/agents/agent_types/). Specifically, it expects either [`BaseSingleActionAgent`](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.BaseSingleActionAgent.html#langchain.agents.agent.BaseSingleActionAgent) or [`BaseMultiAgentAgent`](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.BaseMultiActionAgent.html#langchain.agents.agent.BaseMultiActionAgent)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48ea2803b76d0aba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In [Tree of Thoughts paper](https://arxiv.org/abs/2305.10601), there are two possible workflows for Tree of Thoughts:\n",
    "\n",
    "* *Sample*: $k$ i.i.d. calls to a Thought Generator to get $k$ suggestions\n",
    "* *Propose*: a single call to a Thought Generator to get $k$ suggestions\n",
    "\n",
    "Let's try *Sample* one."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdbc265c18f131b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efc29a3a8c67a5c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generation prompt is adapted from the [original implementation](https://github.com/princeton-nlp/tree-of-thought-llm/blob/master/src/tot/prompts/game24.py)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fe6893c44450186"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['agent_scratchpad', 'inputs', 'previous_thoughts']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample_openai_tools_prompt.input_variables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:18.126149Z",
     "start_time": "2024-03-06T16:52:18.105646Z"
    }
   },
   "id": "dd1b86fc7247919a",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant that plays Game of 24.\n",
      "Human: Your end goal is to obtain 24 from given numbers via basic arithmetic operations. Let's play Game of 24 in a step-by-step fashion: use only one of available tools to suggest a possible next step from the current state. Please, make sure to suggest exactly ONE (1) tool call, no more and no less. Refrain from calling tools only when you're ready to give a final answer. In this case, make sure to include a mathematical expression showing how to obtain 24 from given numbers, for instance: '(2 + 2) * (12 / 2) = 24'\n",
      "Inputs: 2 2 2 8\n",
      "Human: You might have already made some suggestions for the current state - if you did, you will find them below. Don't repeat yourself.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    generate_sample_openai_tools_prompt.format(\n",
    "        inputs=\"2 2 2 8\", agent_scratchpad=[], previous_thoughts=[], max_num_thoughts=5\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:27.072932Z",
     "start_time": "2024-03-06T16:52:27.060244Z"
    }
   },
   "id": "1c3c7ec796c9cd7",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tools\n",
    "\n",
    "For Game of 24, we provide the agent with simple tools performing basic arithmetical operations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fd28a657a9210ca"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tools = [add, subtract, multiply, divide]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:52:31.450925Z",
     "start_time": "2024-03-06T16:52:31.437646Z"
    }
   },
   "id": "fb18a68ffe90be0e",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Putting It All Together\n",
    "\n",
    "Let's use [OpenAI Tools](https://python.langchain.com/docs/modules/agents/agent_types/openai_tools) agent."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8ec4a51f26e768"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.messages import BaseMessage, AIMessage\n",
    "\n",
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser, OpenAIToolAgentAction\n",
    "\n",
    "\n",
    "def format_previous_thoughts(\n",
    "    previous_thoughts: List[Union[List[AgentAction], AgentFinish, AgentAction]]\n",
    ") -> List[BaseMessage]:\n",
    "    messages = []\n",
    "    for agent_action in previous_thoughts:\n",
    "        if isinstance(agent_action, OpenAIToolAgentAction):\n",
    "            new_messages = list(agent_action.message_log)\n",
    "            messages.extend([new for new in new_messages if new not in messages])\n",
    "        elif isinstance(agent_action, list):\n",
    "            messages.extend(format_previous_thoughts(agent_action))\n",
    "        else:\n",
    "            messages.append(AIMessage(content=agent_action.log))\n",
    "    return messages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:53:55.957611Z",
     "start_time": "2024-03-06T16:53:55.939217Z"
    }
   },
   "id": "fb428f3fb5c566c7",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# copied from langchain.agents.create_openai_tools_agent to allow for custom formatting of `previous_thoughts in inputs\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=model_name, temperature=temperature).bind(tools=[convert_to_openai_tool(tool) for tool in tools])\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"inputs\": itemgetter(\"inputs\"),\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(x[\"intermediate_steps\"]),\n",
    "        \"previous_thoughts\": lambda x: format_previous_thoughts(x[\"previous_thoughts\"]),\n",
    "    }\n",
    "    | generate_sample_openai_tools_prompt\n",
    "    | llm\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:53:56.336553Z",
     "start_time": "2024-03-06T16:53:56.316221Z"
    }
   },
   "id": "d48ca4a0c5d0fe71",
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining strategy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8df81acf8ec5b97"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "strategy_executor = TreeOfThoughtsDFSStrategy(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    thought_generator=AgentThoughtGenerator(),\n",
    "    thought_evaluator=thought_evaluator,\n",
    "    max_num_thoughts=max_num_thoughts,\n",
    "    max_iterations=max_num_steps,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:53:56.862336Z",
     "start_time": "2024-03-06T16:53:56.844477Z"
    }
   },
   "id": "3511e290e2ab0d52"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running strategy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62a0d689c7a7e50"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "acc06fffd3a29b30"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new TreeOfThoughtsDFSStrategy chain...\u001B[0m\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_lGEOyFMIwkpHf63DHL4OIQ35\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mstrategy_executor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minputs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m1 1 4 6\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain/chains/base.py:162\u001B[0m, in \u001B[0;36mChain.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    161\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[0;32m--> 162\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    163\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[1;32m    164\u001B[0m final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    165\u001B[0m     inputs, outputs, return_only_outputs\n\u001B[1;32m    166\u001B[0m )\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain/chains/base.py:156\u001B[0m, in \u001B[0;36mChain.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    149\u001B[0m run_manager \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[1;32m    150\u001B[0m     dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    151\u001B[0m     inputs,\n\u001B[1;32m    152\u001B[0m     name\u001B[38;5;241m=\u001B[39mrun_name,\n\u001B[1;32m    153\u001B[0m )\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 156\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    157\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    158\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    159\u001B[0m     )\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    161\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/PycharmProjects/planning-library/planning_library/strategies/base_strategy.py:136\u001B[0m, in \u001B[0;36mBaseCustomStrategy._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;66;03m# We construct a mapping from each tool to a color, used for logging.\u001B[39;00m\n\u001B[1;32m    134\u001B[0m color_mapping \u001B[38;5;241m=\u001B[39m get_color_mapping([tool\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m tool \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtools], excluded_colors\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgreen\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mred\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 136\u001B[0m outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return(output, intermediate_steps, run_manager\u001B[38;5;241m=\u001B[39mrun_manager)\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m output, intermediate_steps \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_strategy(\n\u001B[1;32m    139\u001B[0m         name_to_tool_map\u001B[38;5;241m=\u001B[39mname_to_tool_map,\n\u001B[1;32m    140\u001B[0m         color_mapping\u001B[38;5;241m=\u001B[39mcolor_mapping,\n\u001B[1;32m    141\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    142\u001B[0m         run_manager\u001B[38;5;241m=\u001B[39mrun_manager,\n\u001B[1;32m    143\u001B[0m     )\n\u001B[1;32m    144\u001B[0m ]\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: outputs}\n",
      "File \u001B[0;32m~/PycharmProjects/planning-library/planning_library/strategies/base_strategy.py:136\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;66;03m# We construct a mapping from each tool to a color, used for logging.\u001B[39;00m\n\u001B[1;32m    134\u001B[0m color_mapping \u001B[38;5;241m=\u001B[39m get_color_mapping([tool\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m tool \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtools], excluded_colors\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgreen\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mred\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 136\u001B[0m outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return(output, intermediate_steps, run_manager\u001B[38;5;241m=\u001B[39mrun_manager)\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m output, intermediate_steps \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_strategy(\n\u001B[1;32m    139\u001B[0m         name_to_tool_map\u001B[38;5;241m=\u001B[39mname_to_tool_map,\n\u001B[1;32m    140\u001B[0m         color_mapping\u001B[38;5;241m=\u001B[39mcolor_mapping,\n\u001B[1;32m    141\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    142\u001B[0m         run_manager\u001B[38;5;241m=\u001B[39mrun_manager,\n\u001B[1;32m    143\u001B[0m     )\n\u001B[1;32m    144\u001B[0m ]\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: outputs}\n",
      "File \u001B[0;32m~/PycharmProjects/planning-library/planning_library/strategies/tot_dfs/tot_strategy.py:163\u001B[0m, in \u001B[0;36mTreeOfThoughtsDFSStrategy._run_strategy\u001B[0;34m(self, inputs, name_to_tool_map, color_mapping, run_manager)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m frontier \u001B[38;5;129;01mand\u001B[39;00m cur_step \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iterations:\n\u001B[1;32m    161\u001B[0m     cur_node \u001B[38;5;241m=\u001B[39m frontier\u001B[38;5;241m.\u001B[39mpop()\n\u001B[0;32m--> 163\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m new_thought, observation \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dfs_step(\n\u001B[1;32m    164\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    165\u001B[0m         trajectory\u001B[38;5;241m=\u001B[39mcur_node\u001B[38;5;241m.\u001B[39mtrajectory,\n\u001B[1;32m    166\u001B[0m         run_manager\u001B[38;5;241m=\u001B[39mrun_manager,\n\u001B[1;32m    167\u001B[0m         name_to_tool_map\u001B[38;5;241m=\u001B[39mname_to_tool_map,\n\u001B[1;32m    168\u001B[0m         color_mapping\u001B[38;5;241m=\u001B[39mcolor_mapping,\n\u001B[1;32m    169\u001B[0m     ):\n\u001B[1;32m    170\u001B[0m         new_node \u001B[38;5;241m=\u001B[39m ToTNode(parent\u001B[38;5;241m=\u001B[39mcur_node, thought\u001B[38;5;241m=\u001B[39mnew_thought, observation\u001B[38;5;241m=\u001B[39mobservation)\n\u001B[1;32m    171\u001B[0m         cur_node\u001B[38;5;241m.\u001B[39mchildren\u001B[38;5;241m.\u001B[39mappend(new_node)\n",
      "File \u001B[0;32m~/PycharmProjects/planning-library/planning_library/strategies/tot_dfs/tot_strategy.py:105\u001B[0m, in \u001B[0;36mTreeOfThoughtsDFSStrategy._dfs_step\u001B[0;34m(self, inputs, trajectory, name_to_tool_map, color_mapping, run_manager)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Performs a single step of DFS algorithm.\"\"\"\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# 1: generate k possible next steps\u001B[39;00m\n\u001B[0;32m--> 105\u001B[0m thoughts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthought_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43magent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrajectory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrajectory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_num_thoughts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_num_thoughts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgenerate_thoughts\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# 2: (optional) sort them\u001B[39;00m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdo_sorting:\n",
      "File \u001B[0;32m~/PycharmProjects/planning-library/planning_library/strategies/tot_dfs/components/thought_generators.py:50\u001B[0m, in \u001B[0;36mAgentThoughtGenerator.generate\u001B[0;34m(self, agent, inputs, trajectory, max_num_thoughts, run_manager)\u001B[0m\n\u001B[1;32m     48\u001B[0m results \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_num_thoughts):\n\u001B[0;32m---> 50\u001B[0m     cur_result \u001B[38;5;241m=\u001B[39m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplan\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m        \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrajectory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprevious_thoughts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     results\u001B[38;5;241m.\u001B[39mappend(cur_result)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:486\u001B[0m, in \u001B[0;36mRunnableMultiActionAgent.plan\u001B[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a streaming\u001B[39;00m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;66;03m# fashion to make it possible to get access to the individual LLM tokens\u001B[39;00m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;66;03m# when using stream_log with the Agent Executor.\u001B[39;00m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001B[39;00m\n\u001B[1;32m    484\u001B[0m \u001B[38;5;66;03m# accumulate the output into final output and return that.\u001B[39;00m\n\u001B[1;32m    485\u001B[0m final_output: Any \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 486\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunnable\u001B[38;5;241m.\u001B[39mstream(inputs, config\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks}):\n\u001B[1;32m    487\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m final_output \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m         final_output \u001B[38;5;241m=\u001B[39m chunk\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:2424\u001B[0m, in \u001B[0;36mRunnableSequence.stream\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   2418\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\n\u001B[1;32m   2419\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   2420\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   2421\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   2422\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   2423\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 2424\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(\u001B[38;5;28miter\u001B[39m([\u001B[38;5;28minput\u001B[39m]), config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:2411\u001B[0m, in \u001B[0;36mRunnableSequence.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   2405\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m   2406\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   2407\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[1;32m   2408\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   2409\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   2410\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 2411\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m   2412\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   2413\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform,\n\u001B[1;32m   2414\u001B[0m         patch_config(config, run_name\u001B[38;5;241m=\u001B[39m(config \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m   2415\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2416\u001B[0m     )\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1497\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   1495\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1496\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1497\u001B[0m         chunk: Output \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m final_output_supported:\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:2375\u001B[0m, in \u001B[0;36mRunnableSequence._transform\u001B[0;34m(self, input, run_manager, config)\u001B[0m\n\u001B[1;32m   2366\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m steps:\n\u001B[1;32m   2367\u001B[0m     final_pipeline \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39mtransform(\n\u001B[1;32m   2368\u001B[0m         final_pipeline,\n\u001B[1;32m   2369\u001B[0m         patch_config(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2372\u001B[0m         ),\n\u001B[1;32m   2373\u001B[0m     )\n\u001B[0;32m-> 2375\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m final_pipeline:\n\u001B[1;32m   2376\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m output\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1035\u001B[0m, in \u001B[0;36mRunnable.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   1032\u001B[0m final: Input\n\u001B[1;32m   1033\u001B[0m got_first_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1035\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28minput\u001B[39m:\n\u001B[1;32m   1036\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m got_first_val:\n\u001B[1;32m   1037\u001B[0m         final \u001B[38;5;241m=\u001B[39m chunk\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:4168\u001B[0m, in \u001B[0;36mRunnableBindingBase.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   4162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m   4163\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4164\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[1;32m   4165\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   4166\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m   4167\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 4168\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbound\u001B[38;5;241m.\u001B[39mtransform(\n\u001B[1;32m   4169\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   4170\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_configs(config),\n\u001B[1;32m   4171\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs},\n\u001B[1;32m   4172\u001B[0m     )\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1045\u001B[0m, in \u001B[0;36mRunnable.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   1042\u001B[0m         final \u001B[38;5;241m=\u001B[39m final \u001B[38;5;241m+\u001B[39m chunk  \u001B[38;5;66;03m# type: ignore[operator]\u001B[39;00m\n\u001B[1;32m   1044\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m got_first_val:\n\u001B[0;32m-> 1045\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(final, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:250\u001B[0m, in \u001B[0;36mBaseChatModel.stream\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    244\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_error(\n\u001B[1;32m    245\u001B[0m         e,\n\u001B[1;32m    246\u001B[0m         response\u001B[38;5;241m=\u001B[39mLLMResult(\n\u001B[1;32m    247\u001B[0m             generations\u001B[38;5;241m=\u001B[39m[[generation]] \u001B[38;5;28;01mif\u001B[39;00m generation \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m    248\u001B[0m         ),\n\u001B[1;32m    249\u001B[0m     )\n\u001B[0;32m--> 250\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    252\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_end(LLMResult(generations\u001B[38;5;241m=\u001B[39m[[generation]]))\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:234\u001B[0m, in \u001B[0;36mBaseChatModel.stream\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    232\u001B[0m generation: Optional[ChatGenerationChunk] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream(\n\u001B[1;32m    235\u001B[0m         messages, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    236\u001B[0m     ):\n\u001B[1;32m    237\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\u001B[38;5;241m.\u001B[39mmessage\n\u001B[1;32m    238\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m generation \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:408\u001B[0m, in \u001B[0;36mChatOpenAI._stream\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    405\u001B[0m params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m}\n\u001B[1;32m    407\u001B[0m default_chunk_class \u001B[38;5;241m=\u001B[39m AIMessageChunk\n\u001B[0;32m--> 408\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessage_dicts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    409\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chunk, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    410\u001B[0m         chunk \u001B[38;5;241m=\u001B[39m chunk\u001B[38;5;241m.\u001B[39mdict()\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py:275\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    273\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 275\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py:663\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    611\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    612\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    613\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    661\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    662\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[0;32m--> 663\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    664\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    665\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    666\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m    667\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    683\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    684\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    686\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    687\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    689\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    695\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    696\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/openai/_base_client.py:1200\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1187\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1188\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1195\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1196\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1197\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1198\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1199\u001B[0m     )\n\u001B[0;32m-> 1200\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/openai/_base_client.py:889\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    880\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    881\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    882\u001B[0m     cast_to: Type[ResponseT],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    887\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    888\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m--> 889\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/planning-library-q8r1q5f_-py3.10/lib/python3.10/site-packages/openai/_base_client.py:980\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    977\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m    979\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 980\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m    983\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m    984\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    987\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m    988\u001B[0m )\n",
      "\u001B[0;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_lGEOyFMIwkpHf63DHL4OIQ35\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}"
     ]
    }
   ],
   "source": [
    "strategy_executor.invoke({\"inputs\": \"1 1 4 6\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:53:59.756169Z",
     "start_time": "2024-03-06T16:53:57.909989Z"
    }
   },
   "id": "59924a439f964794"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
